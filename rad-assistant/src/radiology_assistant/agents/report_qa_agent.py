"""
Report QA Agent.

Reviews radiology reports for quality, completeness, consistency, and structure.
"""

import json
import logging
import time
from typing import Optional, List, Dict, Any

from ..config import Config
from ..models import (
    ReportQARequest,
    ReportQAResponse,
    QASeverity,
    QAType,
    QASection,
    QAChangeType,
    QAIssue,
    QASummary
)
from ..llm_client import LLMClient

logger = logging.getLogger(__name__)


REPORT_QA_SYSTEM_PROMPT = """You are a senior, board-certified diagnostic radiologist acting as a quality assurance (QA) reviewer.

Your job:
- Review a single radiology report for QUALITY, COMPLETENESS, CONSISTENCY, and STRUCTURE.
- Return a machine-readable JSON object describing issues and suggested improvements.

Input:
- Exam metadata (modality, body region, patient age/sex where available).
- The full report text as written by the radiologist or generated by an AI.

Key responsibilities:

1. STRUCTURE & COMPLETENESS
- Check that the report has standard sections:
  - TECHNIQUE
  - COMPARISON (if applicable)
  - FINDINGS
  - IMPRESSION
- For the given modality/body region, flag obviously missing critical sections (e.g., IMPRESSION missing).
- If a section is missing but implied, suggest adding it via QAIssue with suggested_change_type = "add_section".

2. CONSISTENCY
- Check for contradictions between FINDINGS and IMPRESSION.
  - Example: FINDINGS mention “small left pleural effusion” but the IMPRESSION says “No pleural effusion”.
- Check for obvious internal inconsistencies (e.g. same lesion with different sizes without explanation).
- Flag these as severity = "critical" or "major" depending on potential clinical impact.

3. CLARITY & STYLE
- Identify excessive hedging or confusing wording that may reduce clinical usefulness.
  - Example: “could represent, possibly, maybe…” all in one sentence.
- Flag unclear or run-on sentences where the meaning could be misinterpreted.
- These are typically severity = "minor" or "info".

4. REDUNDANCY & TERMINOLOGY
- Flag obviously duplicated sentences or sections.
- Flag clearly non-standard, ambiguous, or colloquial terms.
- Do NOT enforce a specific institutional style; focus on clarity and safety.

5. NEUTRALITY ABOUT AI
- You MUST NOT mention AI, large language models, or “as an AI” in any of your outputs.
- You behave as a human radiologist performing QA.

Output format:
Return a single JSON object WITH NO EXTRA TEXT and NO COMMENTS.
JSON structure:

{
  "version": "v1",
  "original_report_text": "<the original report text, exactly as provided>",
  "normalized_report_text": "<optional normalized/cleaned version of the report or null>",
  "issues": [
    {
      "id": "QA1",
      "severity": "critical" | "major" | "minor" | "info",
      "type": "consistency" | "completeness" | "clarity" | "structure" | "redundancy" | "terminology" | "other",
      "section": "TECHNIQUE" | "COMPARISON" | "FINDINGS" | "IMPRESSION" | "OTHER" | "GLOBAL",
      "description": "<short human-readable explanation>",
      "location_hint": "<short snippet or location hint or null>",
      "suggested_change_type": "suggest_edit" | "add_section" | "remove_text" | "reorder" | "note_only",
      "suggested_text": "<replacement or added text, if applicable; otherwise null>"
    }
    // ... more issues
  ],
  "summary": {
    "overall_quality": "good" | "acceptable" | "needs_revision",
    "num_critical": <int>,
    "num_major": <int>,
    "num_minor": <int>,
    "comments": "<optional overall comments or null>"
  }
}

Rules:
- If there are no issues, "issues" must be an empty array and "overall_quality" should generally be "good".
- "normalized_report_text" may be null or a proposed cleaned version with the same clinical meaning as the original.
- NEVER change clinical meaning in suggested_text. Only improve clarity, structure, or fix contradictions that are clearly errors.
- The JSON must be syntactically valid (no trailing commas, valid strings).
"""


class LLMJsonParseError(Exception):
    """Raised when LLM output cannot be parsed as JSON even after retries."""
    pass


class ReportQAAgent:
    def __init__(self, llm_client: LLMClient, logger: Optional[logging.Logger] = None):
        self._llm = llm_client
        self._logger = logger or logging.getLogger(__name__)
        self._system_prompt = REPORT_QA_SYSTEM_PROMPT

    def _build_user_prompt(self, request: ReportQARequest) -> str:
        """Constructs the JSON input string for the LLM."""
        
        # Helper to safely serialize optional list
        required_sections = []
        if request.qa_requirements:
            required_sections = [s.value for s in request.qa_requirements.required_sections]

        input_data = {
            "exam_metadata": {
                "accession": request.exam_metadata.accession,
                "exam_date": str(request.exam_metadata.exam_date) if request.exam_metadata.exam_date else None,
                "modality": request.exam_metadata.modality,
                "body_region": request.exam_metadata.body_region,
                "age": request.exam_metadata.age,
                "sex": request.exam_metadata.sex
            },
            "qa_requirements": {
                "modality": request.qa_requirements.modality if request.qa_requirements else None,
                "body_region": request.qa_requirements.body_region if request.qa_requirements else None,
                "required_sections": required_sections
            },
            "report_text": request.report_text
        }

        return f"""You will receive a single JSON object describing a radiology exam and its report.
Review the report as a QA specialist and respond ONLY with the JSON structure described in the system instructions.

Input JSON:
{json.dumps(input_data, indent=2)}
"""

    def _clean_json(self, text: str) -> str:
        """Clean code blocks from LLM response."""
        text = text.strip()
        if text.startswith("```"):
            lines = text.splitlines()
            if lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            text = "\n".join(lines)
        return text

    def review_report(self, request: ReportQARequest) -> ReportQAResponse:
        """
        Run LLM-based QA on a radiology report and return structured suggestions.
        """
        start = time.monotonic()
        
        user_prompt = self._build_user_prompt(request)

        attempts = 0
        max_retries = 1
        last_error = None
        raw_response = ""

        while attempts <= max_retries:
            attempts += 1
            try:
                # Add retry hint if this is a retry
                current_user_prompt = user_prompt
                if attempts > 1:
                    current_user_prompt += "\n\nError: Invalid JSON returned previously. Please ensure valid JSON format only."

                raw_response = self._llm.generate(
                    system_prompt=self._system_prompt,
                    prompt=current_user_prompt,
                    temperature=0.1,
                    max_tokens=2048,
                )

                cleaned_response = self._clean_json(raw_response)
                payload = json.loads(cleaned_response)
                
                # Pydantic validation
                response = ReportQAResponse(**payload)

                duration = time.monotonic() - start
                
                # Observability log
                self._logger.info(
                    "report_qa_completed",
                    extra={
                        "latency_ms": int(duration * 1000),
                        "num_issues": len(response.issues),
                        "num_critical": response.summary.num_critical,
                        "overall_quality": response.summary.overall_quality
                        # Model name access depends on LLMClient implementation, omitting for safety
                    },
                )

                return response

            except (json.JSONDecodeError, ValueError) as e:
                self._logger.warning(f"Failed to parse QA agent response (attempt {attempts}): {e}")
                last_error = e
        
        # If we get here, all retries failed
        self._logger.error("Failed to parse QA response after retries.")
        raise LLMJsonParseError(f"Failed to parse QA response: {last_error}")
